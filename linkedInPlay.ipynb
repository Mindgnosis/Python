{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "So you want to analyze your Linked In Network"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "You are in luck, as this is what I wanted and already did. Please enjoy the code and hit me up if you have any questions at http://www.mindgnosis.com"
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Read In Keys and Tokens"
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "This is available after you sign on as developer for Linked In here: https://www.linkedin.com/secure/developer\n",
      "The setup is it is stored in a local file myLinkedinCodes.xml file with the format:\n",
      "<LinkedInAuthentication>\n",
      "    <consumerKey>your key</consumerKey>\n",
      "    ...\n",
      "</LinkedInAuthentication>\n",
      "You will have to fill this file out with your own information"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## Initilization: Set Variables and Functions #######################################################################\n",
      "## 1\n",
      "## https://www.linkedin.com/secure/developer\n",
      "################################################################################\n",
      "\n",
      "import oauth2 as oauth\n",
      "import urlparse\n",
      "import BaseHTTPServer \n",
      "import time, os, simplejson\n",
      "from xml.etree import ElementTree as ET\n",
      "\n",
      "http_status_print = BaseHTTPServer.BaseHTTPRequestHandler.responses\n",
      "\n",
      "## Functions ##########################################################################\n",
      "\n",
      "################################################\n",
      "def log_diagnostic_info(client,url,request_headers,method,body,resp,content,error_string):\n",
      "\t# we build up a string, then log it, as multiple calls to () are not guaranteed to be contiguous\n",
      "\tlog = \"\\n\\n[********************LinkedIn API Diagnostics**************************]\\n\\n\"\n",
      "\tlog += \"\\n|-> Status: \" + str(resp.status) + \" <-|\"\n",
      "\tlog += \"\\n|-> \" + simplejson.dumps(error_string) + \" <-|\"\n",
      "\t\n",
      "\tlog += \"\\n|-> Key: \" + CONSUMER_KEY + \" <-|\"\n",
      "\tlog += \"\\n|-> URL: \" + url + \" <-|\"\n",
      "\tlog += \"\\n\\n[*****Sent*****]\\n\";\n",
      "\tlog += \"\\n|-> Headers:\" + simplejson.dumps(request_headers) + \" <-|\"\n",
      "\tif (body):\n",
      "\t\tlog += \"\\n|-> Body: \" + body + \" <-|\"\n",
      "\tlog += \"\\n|-> Method: \" + method + \" <-|\"\n",
      "\tlog += \"\\n\\n[*****Received*****]\\n\"\n",
      "\tlog += \"\\n|-> Response object: \" + simplejson.dumps(resp) + \" <-|\"\n",
      "\tlog += \"\\n|-> Content: \" + content + \" <-|\";\n",
      "\tlog += \"\\n\\n[******************End LinkedIn API Diagnostics************************]\\n\\n\"\n",
      "\tprint log\n",
      "\n",
      "# Simple oauth request wrapper to handle responses and exceptions ##############################################\n",
      "# http://developer.linkedin.com/documents/request-and-response-headers\n",
      "# http://developer.linkedin.com/documents/authentication\n",
      "def make_request(client,url,request_headers={},error_string=\"Failed Request\",method=\"GET\",body=None):\n",
      "\tif body:\n",
      "\t\tresp,content = client.request(url, method, headers=request_headers, body=body)\n",
      "\telse:\n",
      "\t\tresp,content = client.request(url, method, headers=request_headers)\n",
      "\tprint resp.status\n",
      "\t\t\n",
      "\tif resp.status >= 200 and resp.status < 300:\n",
      "\t\treturn content\n",
      "\telif resp.status >= 500 and resp.status < 600:\n",
      "\t\terror_string = \"Status:\\n\\tRuh Roh! An application error occured! HTTP 5XX response received.\"\n",
      "\t\tlog_diagnostic_info(client,url,request_headers,method,body,resp,content,error_string)\n",
      "\t\t\n",
      "\telse:\n",
      "\t\tstatus_codes = {403: \"\\n** Status:\\n\\tA 403 response was received. Usually this means you have reached a throttle limit.\",\n",
      "\t\t\t\t\t\t401: \"\\n** Status:\\n\\tA 401 response was received. Usually this means the OAuth signature was bad.\",\n",
      "\t\t\t\t\t\t405: \"\\n** Status:\\n\\tA 405 response was received. Usually this means you used the wrong HTTP method (GET when you should POST, etc).\",\n",
      "\t\t\t\t\t\t400: \"\\n** Status:\\n\\tA 400 response was received. Usually this means your request was formatted incorrectly or you added an unexpected parameter.\",\n",
      "\t\t\t\t\t\t404: \"\\n** Status:\\n\\tA 404 response was received. The resource was not found.\"}\n",
      "\t\tif resp.status in status_codes:\n",
      "\t\t\tlog_diagnostic_info(client,url,request_headers,method,body,resp,content,status_codes[resp.status])\n",
      "\t\telse:\n",
      "\t\t\tlog_diagnostic_info(client,url,request_headers,method,body,resp,content,http_status_print[resp.status][1])\n",
      "\n",
      "        return( \"ERROR_40X\" )\n",
      "      \n",
      "def get_auth( myKeys = \"myLinkedInCodes.xml\" ): ########################################\n",
      "# http://dataiku.com/blog/2012/12/07/visualizing-your-linkedin-graph-using-gephi-part-1.html\n",
      "\n",
      "    ## Read from input xml\n",
      "    tree = ET.parse( myKeys )\n",
      "    root = tree.getroot()\n",
      "    \n",
      "    ## set keys\n",
      "    CONSUMER_KEY = root.find( \"consumerKey\" ).text\n",
      "    CONSUMER_SECRET = root.find( \"consumerSecret\" ).text\n",
      "    OAUTH_TOKEN = root.find( \"oauthToken\" ).text\n",
      "    OAUTH_TOKEN_SECRET = root.find( \"oauthTokenSecret\" ).text\n",
      "    \n",
      "    #print \"CONSUMER_KEY: \", CONSUMER_KEY\n",
      "    #print \"CONSUMER_SECRET: \", CONSUMER_SECRET\n",
      "    #print \"OAUTH_TOKEN: \", OAUTH_TOKEN\n",
      "    #print \"OAUTH_TOKEN_SECRET: \", OAUTH_TOKEN_SECRET        \n",
      "\n",
      "    # Use your credentials to build the oauth client\n",
      "    consumer = oauth.Consumer(key=CONSUMER_KEY, secret=CONSUMER_SECRET)\n",
      "    token = oauth.Token(key=OAUTH_TOKEN, secret=OAUTH_TOKEN_SECRET)\n",
      "    client = oauth.Client(consumer, token)\n",
      "    return client\n",
      "      \n",
      "#if __name__ == \"__main__\":\n",
      "#    get_auth()    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## File I/O #######################################################\n",
      "## 2\n",
      "## http://docs.python.org/3/tutorial/inputoutput.html#reading-and-writing-files\n",
      "######################################################\n",
      "import codecs\n",
      "\n",
      "def writeFile( content, fileName=\"output.graphml\" ):    \n",
      "    \n",
      "    # File that will store the results\n",
      "    f = open( fileName, 'w')\n",
      "    \n",
      "    #f.write('This is a test\\n')\n",
      "    f.write( content )\n",
      "    f.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Fetching your connections from Linked In and saving it to a local xml: input.xml"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#####################################################################\n",
      "# Getting Data from LinkedIn for the first time and writing it to xml file\n",
      "# 3 - Optional after running once\n",
      "# http://developer.linkedin.com/documents/reading-data#toggleview:id=python\n",
      "##############################\n",
      "\n",
      "client = get_auth() # Get authorization set up and create the OAuth client\n",
      "\n",
      "## Real call for all connections\n",
      "response = make_request(client,\"http://api.linkedin.com/v1/people/~/connections\")\n",
      "writeFile( response, \"input.xml\" )\n",
      "\n",
      "## Testing below #########################################################\n",
      "\n",
      "# Simple connections call Testing\n",
      "#print \"\\n********Get only 2 connections - using parameters********\"\n",
      "#response = make_request(client,\"http://api.linkedin.com/v1/people/~/connections?count=9\")\n",
      "#writeFile( response, \"input9.xml\" )\n",
      "#print response\n",
      "\n",
      "## What does this do\n",
      "#response = make_request(client, \"http://api.linkedin.com/v1/people/FYcdaoNmFc/relation-to-viewer\" )\n",
      "#print response"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 24
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Reading from saved xml and converting it to graphml format"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Note that because Linked In limits how many queries you can make in a 24 hour period, this process will need to be broken out over days.\n",
      "So some of these functions such as initGraphml are only meant to be run one time"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## Structure new Graphml #######################################################\n",
      "## 4 - Optional after running once\n",
      "## http://docs.python.org/2/library/xml.etree.elementtree.html\n",
      "## http://en.wikipedia.org/wiki/GraphML\n",
      "## https://gephi.org/users/supported-graph-formats/graphml-format/\n",
      "## http://docs.python.org/release/2.5.2/ref/strings.html\n",
      "## https://code.google.com/p/systemic-risk/source/browse/trunk/networksimulator/rscripts/sandbox+(prod)/data/example-1-gephi.graphml?r=47\n",
      "######################################################\n",
      "from xml.etree import ElementTree as ET\n",
      "\n",
      "def initGraphml( inFileXML ):\n",
      "\n",
      "    ## new tree\n",
      "    \n",
      "    ## these headers are not necessary for gephi and they break the xml parser\n",
      "    #seedString = '<?xml version=\"1.0\" encoding=\"UTF-8\"?><graphml></graphml>'\n",
      "    \n",
      "    root = ET.fromstring( '<graphml></graphml>' )\n",
      "    \n",
      "    ## same thing with these attributes: break parser and not necessary for gephi\n",
      "    ##root.set( 'xmlns', 'http://graphml.graphdrawing.org/xmlns' )\n",
      "    ##root.set( 'xmlns:xsi' ,'http://www.w3.org/2001/XMLSchema-instance' )\n",
      "    ##root.set( 'xsi:schemaLocation', 'http://graphml.graphdrawing.org/xmlns http://graphml.graphdrawing.org/xmlns/1.0/graphml.xsd' )\n",
      "    \n",
      "    ## Add in all key attributes under graphml node\n",
      "    root.append( ET.fromstring( '\\t<key attr.name=\"label\" attr.type=\"string\" for=\"node\" id=\"label\"/>' ) )\n",
      "    root.append( ET.fromstring( '\\t<key attr.name=\"first-name\" attr.type=\"string\" for=\"node\" id=\"first-name\"/>' ) )\n",
      "    root.append( ET.fromstring( '\\t<key attr.name=\"last-name\" attr.type=\"string\" for=\"node\" id=\"last-name\"/>' ) )\n",
      "    root.append( ET.fromstring( '\\t<key attr.name=\"headline\" attr.type=\"string\" for=\"node\" id=\"headline\"/>' ) )\n",
      "    root.append( ET.fromstring( '\\t<key attr.name=\"picture-url\" attr.type=\"string\" for=\"node\" id=\"picture-url\"/>' ) ) \n",
      "    root.append( ET.fromstring( '\\t<key attr.name=\"api-standard-profile-request\" attr.type=\"string\" for=\"node\" id=\"api-standard-profile-request\"/>' ) ) \n",
      "    root.append( ET.fromstring( '\\t<key attr.name=\"site-standard-profile-request\" attr.type=\"string\" for=\"node\" id=\"site-standard-profile-request\"/>' ) ) \n",
      "    root.append( ET.fromstring( '\\t<key attr.name=\"location\" attr.type=\"string\" for=\"node\" id=\"location\"/>' ) ) \n",
      "    root.append( ET.fromstring( '\\t<key attr.name=\"industry\" attr.type=\"string\" for=\"node\" id=\"industry\"/>' ) ) \n",
      "    \n",
      "        \n",
      "    ## Read from input xml\n",
      "    inTree = ET.parse( inFileXML )\n",
      "    inRoot = inTree.getroot()\n",
      "    \n",
      "    ## convert connections to graph\n",
      "    #print \"inRoot.tag before: \" + root.tag\n",
      "    inRoot.tag = \"graph\"\n",
      "    #print \"inRoot.tag after: \" + root.tag     \n",
      "    \n",
      "    ## add attributes id = \"..\" and edgedefault = \"undirected\"\n",
      "    inRoot.set( 'id', 'myLinkedIn' )\n",
      "    inRoot.set( 'edgedefault', 'undirected' )\n",
      "                \n",
      "    ## move inRoot under \n",
      "    root.append( inRoot )    \n",
      "    return root\n",
      "\n",
      "#if __name__ == \"__main__\":\n",
      "#    gTree = ET.ElementTree( initGraphml( \"input.xml\" ) )\n",
      "#    gTree.write( \"conv.graphml\" )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 23
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Functions such as cleanText are used throughout so will need to be executed each time "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## Stupid characters messing things up #######################################################\n",
      "## 5\n",
      "## https://pypi.python.org/pypi/Unidecode\n",
      "####################################################################\n",
      "from unidecode import unidecode\n",
      "\n",
      "def cleanText( txt ):\n",
      "    \n",
      "    txt = txt.replace( \"&\", \"and\" )\n",
      "    txt = unidecode( txt )\n",
      "    return( txt )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Converts the person format that Linked In xml provides in to GraphML nodes as well as its data columns\n",
      "This is a one time function as you parse the Linked In xml in to the GraphML format"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## Convert Nodes based on Connections #######################################################\n",
      "## 6a - optional\n",
      "## http://docs.python.org/2/library/xml.etree.elementtree.html\n",
      "## http://docs.python.org/2/tutorial/datastructures.html\n",
      "## http://www.tutorialspoint.com/python/string_replace.htm\n",
      "######################################################\n",
      "import xml.etree.ElementTree as ET\n",
      "\n",
      "## changes every child node to data key format ###################################################\n",
      "def convertToDataKey( node ):\n",
      "    \n",
      "    #print \"node.get( id ): \", node.get( \"id\" )   \n",
      "    for kid in node:\n",
      "        \n",
      "        #print \"before: \", kid.tag, \", \", kid.get( \"key\" )\n",
      "        \n",
      "        ## if didn't do this already\n",
      "        if( \"data\" != kid.tag ):\n",
      "            \n",
      "            ## set attribute to tag\n",
      "            kid.set( \"key\", kid.tag )\n",
      "            \n",
      "            ## set tag to key\n",
      "            kid.tag = \"data\"\n",
      "        \n",
      "        #print \"after: \", kid.tag, \", \", kid.get( \"key\" )        \n",
      "        \n",
      "    \n",
      "## convert linkedin xml person to gephi graphml node #################################################################\n",
      "def convertNodes( root ):\n",
      "    \n",
      "    graphNode = root.find( \"graph\" )  \n",
      "    #print \"graphNode.tag: \", graphNode.tag    \n",
      "    \n",
      "    personList = graphNode.findall( \"person\" )\n",
      "    for person in personList:        \n",
      "                \n",
      "        ## convert person to node\n",
      "        person.tag = \"node\" \n",
      "                \n",
      "        ## convert id node to attribute\n",
      "        pId = person.find( \"id\" )\n",
      "        person.set( pId.tag, pId.text )\n",
      "        person.remove( pId )        \n",
      "        #print \"person.id: \", person.get( \"id\" )\n",
      "        \n",
      "        ## set name label\n",
      "        label = person.find( \"first-name\" ).text + \" \" + person.find( \"last-name\" ).text\n",
      "        #print \"label: \", label\n",
      "                        \n",
      "        ## converting child nodes to data key nodes\n",
      "        convertToDataKey( person )        \n",
      "        \n",
      "        ## Have to set attribute after conversion otherwise it will be another unecessary node in the conversion\n",
      "        cleanLabel = cleanText( label )\n",
      "        labelStr = '<data key=\"label\">' + cleanLabel + '</data>'        \n",
      "                \n",
      "        #print \"labelStr: \", labelStr\n",
      "        labelNode = ET.fromstring( labelStr  )        \n",
      "\n",
      "        person.append( labelNode )\n",
      "        \n",
      "    return root\n",
      "\n",
      "###\n",
      "#if __name__ == \"__main__\":\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 19
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The Main function equivalent to convert xml to graphml"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Convert LinkedIn input xml to GraphML ##############################\n",
      "# 6b - Optional after running once\n",
      "# Call this the first time that LinkedIn gives an XML\n",
      "# Since LinkedIn Throttles how many calls you can make in one day\n",
      "##############################\n",
      "import xml.etree.ElementTree as ET\n",
      "\n",
      "client = get_auth() # Get authorization set up and create the OAuth client\n",
      "\n",
      "root = initGraphml( \"input.xml\" )\n",
      "root = convertNodes( root )\n",
      "gTree = ET.ElementTree( root )\n",
      "\n",
      "##############################\n",
      "# write graph\n",
      "##############################\n",
      "gTree.write( \"initial.graphml\" ) "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 20
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "There are a lot of data issues that make cause the process to crash in the middle such as dealing with international characters. This is where a follow function is helpful."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Complete converting GraphML  ##############################\n",
      "# 6c - Optional after running once\n",
      "# Call this if the graphml conversion did not complete for some reason\n",
      "# Prbobaly rare cases where didn't get it right the first time\n",
      "\n",
      "tree = ET.ElementTree()\n",
      "tree.parse( \"initial.graphml\" )\n",
      "root = tree.getroot()    \n",
      "root = convertNodes( root )    \n",
      "tree.write( \"nextToFinal.graphml\" )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 21
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Read from the saved graphml file and find edges for each connection"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Again it is important to note the throttling limitations of Linked In\n",
      "Unless you have a small network less than 400, it will most likely take multiple days to complete\n",
      "So you must visualize the process as broken out in pieces"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## Write edges based on connections between connections #######################################################\n",
      "## 7\n",
      "## http://dataiku.com/blog/2012/12/07/visualizing-your-linkedin-graph-using-gephi-part-1.html\n",
      "## http://developer.linkedin.com/documents/people-search-api#\n",
      "## http://developer.linkedin.com/thread/2286\n",
      "## http://www.tutorialspoint.com/python/time_sleep.htm\n",
      "## http://developer.linkedin.com/documents/throttle-limits\n",
      "######################################################\n",
      "from xml.etree.ElementTree import fromstring, Element\n",
      "import xml.etree.ElementTree as ET\n",
      "\n",
      "#LINKED_IN_PARAMS = \":(relation-to-viewer:(related-connections))\"\n",
      "LINKED_IN_PARAMS = '/relation-to-viewer'\n",
      "\n",
      "## https://www.linkedin.com/secure/developer\n",
      "THROTTLE_LIMIT = 200 ## at this point, should just quit out and write what you got so far\n",
      "\n",
      "###########################################################################\n",
      "def getEdges( idStr, client ):\n",
      "    \n",
      "    ## asks for all the connections that share a connection to the idStr\n",
      "    reqStr = \"http://api.linkedin.com/v1/people/id=\" + idStr + LINKED_IN_PARAMS\n",
      "    edgeResponse = make_request( client, reqStr )\n",
      "    #print \"edgeResponse str: \", edgeResponse\n",
      "    \n",
      "    respNode = ET.fromstring( cleanText( edgeResponse ) )\n",
      "    \n",
      "    respTree = ET.ElementTree( respNode )\n",
      "    respRoot = respTree.getroot()\n",
      "    #print \"respRoot: \",  respRoot\n",
      "    #ET.dump( respTree )\n",
      "               \n",
      "    cList = respRoot.findall( \".//id\" )\n",
      "    \n",
      "    return( cList )    \n",
      "\n",
      "###############################################################################\n",
      "## Takes a list of nodes and truncates all nodes up to lastNode\n",
      "def getNodesAfter( nList, lastNode ):\n",
      "# http://docs.python.org/2/tutorial/datastructures.html    \n",
      "        \n",
      "    #print \"nList len: \", len( nList )    \n",
      "    \n",
      "    lastNodeIndex = nList.index( lastNode )\n",
      "    #print \"lastNodeIndex: \", lastNodeIndex\n",
      "    if( 0 < lastNodeIndex ):\n",
      "        cList = nList[ lastNodeIndex + 1:len( nList ) ]\n",
      "        #print \"cList length: \", len( cList )\n",
      "        #print \"cList[ 0 ].get( id ): \", cList[ 0 ].get( \"id\" )\n",
      "        return( cList )\n",
      "    \n",
      "    return( nList )\n",
      "\n",
      "#################################################################################\n",
      "## Takes an existing graph, iterates through its nodes, and add edges of mutual connections\n",
      "def addEdges( root, client, lastNodeId = \"\" ):\n",
      "       \n",
      "    graphNode = root.find( \"graph\" )\n",
      "    \n",
      "    # Find the nodes with an id attribute\n",
      "    # can't work on the runway as the plane is taking off\n",
      "    nodes = graphNode.findall( \"./node[@id]\" )    \n",
      "    #print \"nodes lenght: \", len( nodes )\n",
      "    \n",
      "    \n",
      "    ## if second time around, then remove previously processed nodes\n",
      "    if( \"\" != lastNodeId ):\n",
      "        #print \"nodes lenght before: \", len( nodes )\n",
      "        lastNode = graphNode.find( \"./node[@id='\" + lastNodeId + \"']\" )\n",
      "        #print \"lastNode.get( id ): \", lastNode.get( \"id\" )        \n",
      "        nodes = getNodesAfter( nodes,  lastNode )\n",
      "        #print \"nodes lenght after: \", len( nodes )\n",
      "            \n",
      "    ## parse through list of node ids and find edges for it ####################    \n",
      "    \n",
      "    # Tracking calls to handle throttlings\n",
      "    totalCalls = 1        \n",
      "    \n",
      "    for node in nodes:         \n",
      "        \n",
      "        ## Closing out before LinkedIn's API limit ###########################  \n",
      "        if( THROTTLE_LIMIT < totalCalls ):                        \n",
      "            print \"Take a break before throttling-----------------------\"\n",
      "            return( graphNode )        \n",
      "        \n",
      "        ## Iterate through ids and find mutual connections #####################\n",
      "        sourceId = node.get( \"id\" )\n",
      "        print totalCalls, \": working on id: \", sourceId \n",
      "        \n",
      "        if( \"private\" != sourceId ): ## Skipping private IDs           \n",
      "            \n",
      "            ## getting edges ##########################\n",
      "            conIds = getEdges( sourceId, client )\n",
      "            #conIds = [] # for tracing\n",
      "            \n",
      "            ## quit out with what we have if encountered an Error ######\n",
      "            if( \"ERROR_40X\" == conIds ):\n",
      "                print \"LinkedIn API error out============================\"\n",
      "                return( graphNode )\n",
      "            \n",
      "            ## add new edges if found any ######################################\n",
      "            if( 0 < len( conIds ) ):                \n",
      "                for tarId in conIds:                                                                \n",
      "                    if( \"private\" != tarId.text ): ## Skipping private IDs                        \n",
      "                        partnerId = cleanText( sourceId + \"_\" + tarId.text )\n",
      "                        strElem = '<edge id = \"' + partnerId + '\" source = \"' + sourceId + '\" target = \"' + tarId.text + '\" />'\n",
      "                        #print \"strElem: \", strElem                    \n",
      "                        graphNode.append( ET.fromstring( strElem ) )\n",
      "        \n",
      "        totalCalls = totalCalls + 1\n",
      "    \n",
      "    return( root  )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 22
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Main file equivalent for adding edges"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Pay close attention to the output generated from running this cell\n",
      "It will report on which id it is processing. You will need to record the last node that was processed to continue the next time.\n",
      "The LAST_NODE_ID is the id of the last node processed before quitting intentionally or not\n",
      "\n",
      "If you don't do this and you have a network that is larger than your Linked In throttle limit, then you will never finish."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#####################################################################\n",
      "# Read in GraphML and finish adding edges\n",
      "# 8\n",
      "# It is important to update LAST_NODE_ID, Reading from and Writing to each time\n",
      "# Since LinkedIn Throttles how many calls you can make in one day\n",
      "# This is meant to be called on a seperate day to parse through the rest of the list of person nodes\n",
      "##############################\n",
      "from xml.etree import ElementTree as ET\n",
      "\n",
      "LAST_NODE_ID = \"\" ## Manually set this to the id of the last node processed\n",
      "\n",
      "client = get_auth() # Get authorization set up and create the OAuth client\n",
      "\n",
      "##############################\n",
      "# read from graphml\n",
      "##############################\n",
      "gTree = ET.parse( \"nextToFinal.graphml\" )\n",
      "graph = gTree.getroot()\n",
      "\n",
      "##############################\n",
      "# Add Edges\n",
      "##############################\n",
      "newGraph = addEdges( graph, client, LAST_NODE_ID )\n",
      "gTree = ET.ElementTree( newGraph )\n",
      "\n",
      "##############################\n",
      "# write graph\n",
      "##############################\n",
      "#ET.dump( gTree )\n",
      "gTree.write( \"final.graphml\" ) "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}